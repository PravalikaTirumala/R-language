Pravalika Tirumala
cwid: 50180701
Week 7 Assignment
K-Nearest Neighbors (KNN)


Part 0: Install "class" package for the knn() function required in this assignment.
	> install.packages("class")


Part 1. Download the zip file churnData.zip from Doc Sharing. The zip file contains two files, churnTrain.csv and churnTest.csv to be used in knn training 
and testing.
	Downloaded

Part 2. Load data from churnTrain.csv and  churnTest.csv into data frames trainingData and testingData.
	> TrainingData<-read.csv("E:/1 FALL 2017/data analysis and visualization/NOT YET SUBMITTED/churnTrain.csv")
	> TestData<-read.csv("E:/1 FALL 2017/data analysis and visualization/NOT YET SUBMITTED/churnTest.csv")


Part 3. Create two vectors to hold values of  churn columns of training and test data frames created in Step 2.
Hint: There are few ways to accomplish this. For example, if the name of data frame for training set is trainingData, then you can extract its the churn 
column values into a vector as follows:trainingDataLabels <- tariningData[,c("chrun")] Similarly, for test data create a vector for the churn column.
	> TrainingDatachvec<-TrainingData[,c("churn")]
	> TestDatachvec<-TestData[,c("churn")]


Part 4: Remove the columns churn, state, account_length, and area_code from both training and test data frames.
	For TrainingData:
	> ncol(TrainingData)
	[1] 20
	> TrainingData<-TrainingData[, -c(1:3)]	#removes first 3 columns
	> TrainingData$churn<-NULL				#removes churn column
	> ncol(TrainingData)
	[1] 16									#After removing 4 columns

	For TestData:
	> ncol(TestData)
	[1] 20
	> TestData<-subset(TestData, ,-c(churn, state, account_length,area_code))
	> ncol(TestData)
	[1] 16



Part 5: Replace yes and no values of the voice_mail_plan and international_plan attributes in both the training and test data frames to 1 and 0. In other 
words replace yes with 1 and no with 0.
	>  TrainingData$voice_mail_plan<-ifelse(TrainingData$voice_mail_plan=="yes","1","0")
	>  TrainingData$international_plan<-ifelse(TrainingData$international_plan=="yes","1","0")
	
	>  TestData$voice_mail_plan<-ifelse(TestData$voice_mail_plan=="yes","1","0")
	>  TestData$international_plan<-ifelse(TestData$international_plan=="yes","1","0")
	
	

Part 6. Apply knn()
A) Apply knn function with k=3.
knn(train=trainingData, test=testingData,cl=tariningDataLabels, k=3)
Note that knn function returns the predicted class labels for the test data.
	>  library(class)
	>  knnval<-knn(train=TrainingData,test=TestData,cl=TrainingDatachvec,k=3)


B) Compute the number of incorrect labels.
Any label that is not correctly classified by knn() is called an incorrect label. So, to find the number of incorrect labels you need to compare the result 
of knn() call with the labels of the test data used in knn().
	> incorrectVal<-100*sum(TestDatachvec != knnval)/100
	> incorrectVal
	[1] 194
	
	
C) Compute the misclassification rate
The misclassification rate is the ratio of the number of incorrectly labeled values to the number of all labels in the test data set.
	> miscalrate=incorrectVal/length(TestDatachvec)
	> miscalrate
	[1] 0.1163767

D) Repeat A, B, and C using k=5. Is there a significant change in prediction of correct labels when compared to the case of k=3?
	> knnval5<-knn(train=TrainingData,test=TestData,cl=TrainingDatachvec,k=5)
	> incorrectVal5<-100*sum(TestDatachvec != knnval5)/100
	> incorrectVal5
	[1] 165
	> miscalrate5=incorrectVal5/length(TestDatachvec)
	> miscalrate5
	[1] 0.0989802

	Yes there is a change in prediction, with k=5: Number of Incorrect predictions are decreased by 29, miscalculation rate is decreased by 0.01739 and correct 
	valuesincreased by 29.
	

Part 7. Compute Model Performance
Use table() function to  evaluate the model performance by printing the predicted class labels(returned by knn function) versus the real class labels in the 
test data.
A)  Based on the result of the call to the table, what percentage of the data was correctly classified by knn()?
	> perf<-table(knnval,TestDatachvec)
	> perf
		TestDatachvec
	knnval   no  yes
		no  1399  150
		yes   44   74
	
	> correctpredval<-1399+74
	> correctpredval
	[1] 1473
	> sum<-1399+150+44+74
	> sum
	[1] 1667
	> corrperc<-(correctpredval/sum)*100
	> corrperc
	[1] 88.36233

		(or)

	> correcVal<-100*sum(TestDatachvec == knnval)/100
	> correcVal
	[1] 1473
	> corrcalrate<-correcVal/length(TestDatachvec)
	> corrcalrate
	[1] 0.8836233
	> print(corrcalrate*100)
	[1] 88.36233
	
	88% of the data was corectly classified.
	
	
Part 8. Compute the accuracy of the knn.
Accuracy is the ratio of the number of correct labels to the total number of labels. Accuracy is 1-Misclassification Rate
	> accuracy<-correcVal/length(TestDatachvec)
	> accuracy
	[1] 0.8836233
	
	(or)
	
	> accuracy1<-(1-miscalrate)
	> accuracy1
	[1] 0.8836233


Part 9. Standardize the data and apply knn.  Because the KNN classifier predicts the class of a given test observation by identifying the observations that 
are nearest to it, the scale of the variables matters. Any variables that are on a large scale will have a much larger effect on the distance between the 
observations, and hence on the KNN classifier, than variables that are on a small scale.
A) Use scale() function to standardize training data (trainingData) and test data (testingData). Then apply knn one more time to classify data. Next, use 
table() function to  evaluate the model performance by printing the predicted class labels(returned by knn function) versus the real class labels in the test 
data. Is there any improvement when compared to non-standardized case(i.e., results obtained in Part 6 and Part 7)?

	In TrainingData and TestData, there are only 2 columns which are of type character: international_plan, voice_mail_plan
	Convert these to numeric:
	> TrainingData$international_plan<-as.numeric(TrainingData$international_plan)
	> TrainingData$voice_mail_plan<-as.numeric(TrainingData$voice_mail_plan)
	> TestData$international_plan<-as.numeric(TestData$international_plan)
	> TestData$voice_mail_plan<-as.numeric(TestData$voice_mail_plan)
	
	> scaleTrainingData<-scale(TrainingData)
	> scaleTestData<-scale(TestData)
	
	For k=3:
	> knnscale<-knn(train=TrainingData,test=TestData,cl=TrainingDatachvec,k=3)
	> scaleperf<-table(knnscale,TestDatachvec)
	> scaleperf
			TestDatachvec
	knnscale   no  yes
		no    1399  150
		yes    44   74
		
	> incorrecvals<-length(TestDatachvec)-corrvals
	> incorrecvals
	[1] 194
	> miscalratescle= incorrecvals/length(TestDatachvec)
	> miscalratescle
	[1] 0.1163767
	
	For k=5: mis calculation rate is -0.09898
	
	Hence there is no change or improvement when compared to non standardized case.


